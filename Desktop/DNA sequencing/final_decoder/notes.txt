Probability of substitution different for each index based on sparsifier changes

Use probability of sparse sequence with product rule to get codeword probabilities

Sum codeword probabilities to get log likelihoods

#Mention Kates work for the watermark encoding motviation - better than marker coding because its better in the DNA application
#The Watermarks provide more indexing which is more robust against changes from insertion/deletion channel and we can figure out
#which watermark it was, however this does greatly reduce the rate.


1. Create a new backwards stack algorithm ✅
2. Connect the sparsifier substitution distribution to the Trellis3D ✅
3. Include effects of deletions ✅
4. Remove Insertion --> Deletion Trellis edges and vice versa? ✅
5. Create a Sparsifier decoder using product over each different sequence then sum over column of mappings
6. Sparsifier decoder likelhoods for codewords
7. Input codeword likelhoods into ldpc decoder to get ouput likelhoods and use thresholding to get results
8. Iterative Trellis decoding?? Priori of output likelihoods for codeword converted to priori of sparse sequences 
which is multiplied by (2.) sparsifier substitution distribution and normalised